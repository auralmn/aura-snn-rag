{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Memory Seeding & One-Shot Recall\n",
    "- Load trained model.\n",
    "- Ingest JSONL/CSV corpora into hippocampal memory.\n",
    "- Test one-shot recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q torch datasets transformers sentencepiece tqdm\n",
    "import torch, sys\n",
    "from pathlib import Path\n",
    "ROOT = Path('/content/repo') if Path('/content/repo').exists() else Path.cwd().parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "from colab_l4_training import get_test_config, main, ingest_jsonl_to_memory, ingest_csv_pairs_to_memory, one_shot_memorize_and_generate\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (short run or load checkpoint if you have one)\n",
    "config = get_test_config()\n",
    "config.enable_continuous_learning = False\n",
    "model, losses, cl_orch = main(config_preset='test')\n",
    "hippocampus = model.hippocampus\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base', legacy=True)\n",
    "print('Hippocampus memories:', hippocampus.memory_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest JSONL corpora into episodic memory\n",
    "jsonl_paths = [\n",
    "    ROOT/'vocab_src/instruct_55k_clean.jsonl',\n",
    "    ROOT/'vocab_src/OpenThoughts-114k.jsonl',\n",
    "    ROOT/'vocab_src/principles_texts.jsonl',\n",
    "]\n",
    "for p in jsonl_paths:\n",
    "    if p.exists():\n",
    "        stored = ingest_jsonl_to_memory(str(p), tokenizer, model, hippocampus, device, max_items=500)\n",
    "        print(p.name, 'stored', stored)\n",
    "\n",
    "# Ingest CSV Q/A pairs (e.g., timeline conversations)\n",
    "csv_path = ROOT/'vocab_src/timeline_conversations.csv'\n",
    "if csv_path.exists():\n",
    "    stored = ingest_csv_pairs_to_memory(str(csv_path), tokenizer, model, hippocampus, device, max_items=500)\n",
    "    print(csv_path.name, 'stored', stored)\n",
    "\n",
    "print('Total memories:', hippocampus.memory_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-shot recall test\n",
    "support = \"Quantum entanglement links particles across any distance.\"\n",
    "prompt = \"Explain entanglement to a student\"\n",
    "generated = one_shot_memorize_and_generate(support, prompt, tokenizer, model, hippocampus, device)\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
