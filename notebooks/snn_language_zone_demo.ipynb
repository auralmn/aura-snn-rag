{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SNN Language Zone Demo: Prosody-Driven Attention\n",
                "\n",
                "This notebook demonstrates the **Spiking Neural Network (SNN) Language Zone** with **Multi-Channel Prosody Attention** on:\n",
                "1. **GoEmotions** (text emotion classification) - primary demo\n",
                "2. **MNIST** (digit recognition) - baseline comparison\n",
                "\n",
                "## Components Showcased\n",
                "- Multi-Channel Spiking Attention (amplitude/pitch/boundary)\n",
                "- Prosody-Modulated GIF Neurons\n",
                "- SNN Transformer Operations\n",
                "- Spike⇄Continuous Bridges"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if needed\n",
                "# !pip install torch torchvision datasets transformers numpy matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../')  # Add parent directory to path\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from datasets import load_dataset\n",
                "from transformers import AutoTokenizer\n",
                "from torch.utils.data import DataLoader, Subset\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "\n",
                "# Import SNN Language Zone components\n",
                "from src.core.language_zone.prosody_attention import ProsodyAttentionBridge\n",
                "from src.core.language_zone.prosody_gif import ProsodyModulatedGIF\n",
                "from src.core.language_zone.full_language_zone import FullLanguageZone\n",
                "from src.core.language_zone.gif_neuron import GIFNeuron\n",
                "from src.core.language_zone.synapsis import Synapsis\n",
                "\n",
                "print(\"✅ Imports successful\")\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 1: GoEmotions Text Classification\n",
                "\n",
                "GoEmotions is a dataset of 58k Reddit comments labeled with 28 emotions. Perfect for demonstrating prosody-driven attention!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load GoEmotions dataset\n",
                "print(\"Loading GoEmotions dataset...\")\n",
                "dataset = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")\n",
                "\n",
                "# Take a small subset for quick demo\n",
                "train_data = dataset['train'].select(range(1000))\n",
                "test_data = dataset['test'].select(range(200))\n",
                "\n",
                "print(f\"Train samples: {len(train_data)}\")\n",
                "print(f\"Test samples: {len(test_data)}\")\n",
                "print(f\"\\nExample:\")\n",
                "print(f\"Text: {train_data[0]['text']}\")\n",
                "print(f\"Labels: {train_data[0]['labels']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize emotion distribution\n",
                "emotion_names = [\n",
                "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion',\n",
                "    'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
                "    'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness',\n",
                "    'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
                "]\n",
                "\n",
                "# Count labels\n",
                "label_counts = [0] * 28\n",
                "for sample in train_data:\n",
                "    for label in sample['labels']:\n",
                "        label_counts[label] += 1\n",
                "\n",
                "plt.figure(figsize=(15, 5))\n",
                "plt.bar(range(28), label_counts)\n",
                "plt.xticks(range(28), emotion_names, rotation=45, ha='right')\n",
                "plt.ylabel('Count')\n",
                "plt.title('Emotion Distribution in Training Set')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prosody Extraction Demo\n",
                "\n",
                "Let's see how prosody channels are extracted from emotional text."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize prosody attention bridge\n",
                "prosody_bridge = ProsodyAttentionBridge(\n",
                "    attention_preset='emotional',  # High sensitivity to emotional content\n",
                "    k_winners=5\n",
                ")\n",
                "\n",
                "# Example texts with different emotional content\n",
                "test_texts = [\n",
                "    \"This is AMAZING! I absolutely love it!\",\n",
                "    \"I'm so disappointed and sad about this.\",\n",
                "    \"The quick brown fox jumps over the lazy dog.\",\n",
                "    \"WOW! This is incredible! Best day ever!!!\"\n",
                "]\n",
                "\n",
                "for i, text in enumerate(test_texts):\n",
                "    # Tokenize (simple whitespace split for demo)\n",
                "    tokens = text.split()\n",
                "    \n",
                "    # Extract prosody channels\n",
                "    amp, pitch, boundary = prosody_bridge.extract_prosody(tokens)\n",
                "    \n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Text {i+1}: {text}\")\n",
                "    print(f\"Tokens: {tokens}\")\n",
                "    print(f\"Amplitude (CAPS/!): {amp}\")\n",
                "    print(f\"Pitch (emotive/?): {pitch}\")\n",
                "    print(f\"Boundary (punct): {boundary}\")\n",
                "    \n",
                "    # Compute attention\n",
                "    token_ids = list(range(len(tokens)))\n",
                "    result = prosody_bridge.compute_attention_gains(\n",
                "        token_ids=token_ids,\n",
                "        token_strings=tokens\n",
                "    )\n",
                "    \n",
                "    print(f\"Salience: {result['salience']}\")\n",
                "    print(f\"Winner indices: {result['winners_idx']}\")\n",
                "    print(f\"Winner tokens: {[tokens[i] for i in result['winners_idx']]}\")\n",
                "    print(f\"Attention gain (μ): {result['mu_scalar']:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize prosody channels\n",
                "text_idx = 0  # \"This is AMAZING! I absolutely love it!\"\n",
                "tokens = test_texts[text_idx].split()\n",
                "amp, pitch, boundary = prosody_bridge.extract_prosody(tokens)\n",
                "\n",
                "fig, axes = plt.subplots(3, 1, figsize=(12, 6), sharex=True)\n",
                "\n",
                "axes[0].stem(amp, basefmt=' ')\n",
                "axes[0].set_ylabel('Amplitude')\n",
                "axes[0].set_title('Prosody Channels: \"' + test_texts[text_idx] + '\"')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "axes[1].stem(pitch, basefmt=' ', linefmt='C1-', markerfmt='C1o')\n",
                "axes[1].set_ylabel('Pitch')\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "axes[2].stem(boundary, basefmt=' ', linefmt='C2-', markerfmt='C2o')\n",
                "axes[2].set_ylabel('Boundary')\n",
                "axes[2].set_xlabel('Token Index')\n",
                "axes[2].set_xticks(range(len(tokens)))\n",
                "axes[2].set_xticklabels(tokens, rotation=45, ha='right')\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## GIF Neuron Modulation Demo\n",
                "\n",
                "Show how prosody modulates spiking behavior."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create GIF neurons with/without prosody modulation\n",
                "gif_standard = GIFNeuron(input_dim=64, hidden_dim=128, L=16)\n",
                "gif_prosody = ProsodyModulatedGIF(\n",
                "    input_dim=64, \n",
                "    hidden_dim=128, \n",
                "    L=16,\n",
                "    attention_modulation_strength=0.5  # Strong modulation for demo\n",
                ")\n",
                "\n",
                "# Create test input\n",
                "batch_size = 1\n",
                "seq_len = 20\n",
                "x = torch.randn(batch_size, seq_len, 64)\n",
                "\n",
                "# Case 1: No attention (baseline)\n",
                "spikes_baseline, _ = gif_standard(x)\n",
                "\n",
                "# Case 2: Uniform attention\n",
                "attention_uniform = torch.ones(batch_size, seq_len)\n",
                "spikes_uniform, _ = gif_prosody(x, attention_gains=attention_uniform)\n",
                "\n",
                "# Case 3: High attention on some timesteps (simulating emotional content)\n",
                "attention_emotional = torch.ones(batch_size, seq_len)\n",
                "attention_emotional[0, 5:10] = 3.0  # High attention for \"emotional\" timesteps\n",
                "spikes_emotional, _ = gif_prosody(x, attention_gains=attention_emotional)\n",
                "\n",
                "# Visualize spike counts\n",
                "plt.figure(figsize=(14, 4))\n",
                "\n",
                "plt.subplot(1, 3, 1)\n",
                "plt.imshow(spikes_baseline[0].T.detach().numpy(), aspect='auto', cmap='hot')\n",
                "plt.colorbar(label='Spike count')\n",
                "plt.title('Standard GIF (no modulation)')\n",
                "plt.ylabel('Neuron Index')\n",
                "plt.xlabel('Time')\n",
                "\n",
                "plt.subplot(1, 3, 2)\n",
                "plt.imshow(spikes_uniform[0].T.detach().numpy(), aspect='auto', cmap='hot')\n",
                "plt.colorbar(label='Spike count')\n",
                "plt.title('Prosody GIF (uniform attention)')\n",
                "plt.xlabel('Time')\n",
                "\n",
                "plt.subplot(1, 3, 3)\n",
                "plt.imshow(spikes_emotional[0].T.detach().numpy(), aspect='auto', cmap='hot')\n",
                "plt.colorbar(label='Spike count')\n",
                "plt.title('Prosody GIF (emotional peaks)')\n",
                "plt.xlabel('Time')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Print statistics\n",
                "print(f\"Spike counts:\")\n",
                "print(f\"  Baseline: {spikes_baseline.sum():.0f}\")\n",
                "print(f\"  Uniform attention: {spikes_uniform.sum():.0f}\")\n",
                "print(f\"  Emotional peaks: {spikes_emotional.sum():.0f}\")\n",
                "print(f\"\\nSpikes during emotional peak (t=5-10):\")\n",
                "print(f\"  Baseline: {spikes_baseline[0, 5:10].sum():.0f}\")\n",
                "print(f\"  Emotional: {spikes_emotional[0, 5:10].sum():.0f}\")\n",
                "print(f\"  Ratio: {spikes_emotional[0, 5:10].sum() / (spikes_baseline[0, 5:10].sum() + 1e-8):.2f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Full Language Zone Demo on GoEmotions\n",
                "\n",
                "Train a simple classifier using the prosody-driven SNN."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple tokenizer (character-level for demo)\n",
                "class SimpleCharTokenizer:\n",
                "    def __init__(self, vocab_size=128):\n",
                "        self.vocab_size = vocab_size\n",
                "    \n",
                "    def encode(self, text, max_len=50):\n",
                "        # Convert to ASCII codes\n",
                "        tokens = [min(ord(c), self.vocab_size-1) for c in text[:max_len]]\n",
                "        # Pad\n",
                "        tokens = tokens + [0] * (max_len - len(tokens))\n",
                "        return tokens\n",
                "    \n",
                "    def get_token_strings(self, text, max_len=50):\n",
                "        # Return words for prosody extraction\n",
                "        words = text.split()[:max_len]\n",
                "        return words + [''] * (max_len - len(words))\n",
                "\n",
                "tokenizer = SimpleCharTokenizer(vocab_size=256)\n",
                "\n",
                "# Test tokenization\n",
                "sample_text = \"This is amazing!\"\n",
                "tokens = tokenizer.encode(sample_text, max_len=20)\n",
                "print(f\"Sample text: {sample_text}\")\n",
                "print(f\"Token IDs: {tokens[:len(sample_text)]}\")\n",
                "print(f\"Decoded: {''.join([chr(t) for t in tokens if t > 0])}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create emotion classifier\n",
                "class EmotionClassifier(nn.Module):\n",
                "    def __init__(self, vocab_size=256, embed_dim=64, hidden_dim=128, num_emotions=28):\n",
                "        super().__init__()\n",
                "        \n",
                "        # Use prosody-modulated language zone\n",
                "        self.language_zone = FullLanguageZone(\n",
                "            vocab_size=vocab_size,\n",
                "            embed_dim=embed_dim,\n",
                "            hidden_dim=hidden_dim,\n",
                "            attention_preset='emotional',  # High prosody sensitivity\n",
                "            num_experts=4  # Small for demo\n",
                "        )\n",
                "        \n",
                "        # Classification head\n",
                "        self.classifier = nn.Linear(vocab_size, num_emotions)\n",
                "    \n",
                "    def forward(self, input_ids, token_strings=None):\n",
                "        # Get language zone output\n",
                "        logits, info = self.language_zone(input_ids, token_strings)\n",
                "        \n",
                "        # Pool over sequence (mean)\n",
                "        pooled = logits.mean(dim=1)  # (batch, vocab_size)\n",
                "        \n",
                "        # Classify\n",
                "        emotion_logits = self.classifier(pooled)\n",
                "        \n",
                "        return emotion_logits, info\n",
                "\n",
                "model = EmotionClassifier().to(device)\n",
                "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick inference test\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    # Prepare sample\n",
                "    text = \"This is absolutely amazing! I love it!\"\n",
                "    token_ids = torch.tensor([tokenizer.encode(text, max_len=30)]).to(device)\n",
                "    token_strings = [tokenizer.get_token_strings(text, max_len=30)]\n",
                "    \n",
                "    # Forward pass\n",
                "    emotion_logits, info = model(token_ids, token_strings)\n",
                "    \n",
                "    print(f\"Input: {text}\")\n",
                "    print(f\"\\nProsody stats:\")\n",
                "    print(f\"  Mean gain: {info['prosody_stats']['mean_gain']:.3f}\")\n",
                "    print(f\"  Max gain: {info['prosody_stats']['max_gain']:.3f}\")\n",
                "    print(f\"  Winner tokens: {info['attention']['winners'][0]}\")\n",
                "    \n",
                "    # Top predicted emotions\n",
                "    probs = torch.softmax(emotion_logits, dim=-1)\n",
                "    top5 = torch.topk(probs[0], 5)\n",
                "    print(f\"\\nTop 5 predicted emotions:\")\n",
                "    for val, idx in zip(top5.values, top5.indices):\n",
                "        print(f\"  {emotion_names[idx]}: {val:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Comparing Attention Presets\n",
                "\n",
                "Show how different presets affect attention."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test different presets\n",
                "presets = ['analytical', 'emotional', 'historical', 'streaming']\n",
                "text = \"WOW! This is absolutely INCREDIBLE and AMAZING!\"\n",
                "tokens = text.split()\n",
                "token_ids = list(range(len(tokens)))\n",
                "\n",
                "results = {}\n",
                "for preset in presets:\n",
                "    bridge = ProsodyAttentionBridge(attention_preset=preset, k_winners=3)\n",
                "    result = bridge.compute_attention_gains(token_ids, tokens)\n",
                "    results[preset] = result\n",
                "\n",
                "# Plot comparison\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, preset in enumerate(presets):\n",
                "    sal = results[preset]['salience']\n",
                "    winners = results[preset]['winners_idx']\n",
                "    \n",
                "    axes[i].bar(range(len(tokens)), sal, color=['red' if j in winners else 'blue' for j in range(len(tokens))])\n",
                "    axes[i].set_title(f'{preset.capitalize()} (μ={results[preset][\"mu_scalar\"]:.2f})')\n",
                "    axes[i].set_xticks(range(len(tokens)))\n",
                "    axes[i].set_xticklabels(tokens, rotation=45, ha='right')\n",
                "    axes[i].set_ylabel('Salience')\n",
                "    axes[i].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Annotate winners\n",
                "    for w in winners:\n",
                "        axes[i].text(w, sal[w] + 0.05, '★', ha='center', fontsize=16, color='red')\n",
                "\n",
                "plt.suptitle(f'Attention Preset Comparison: \"{text}\"', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 2: MNIST Baseline (Vision)\n",
                "\n",
                "Quick demo using SNN components for digit recognition."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load MNIST\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "mnist_train = torchvision.datasets.MNIST(\n",
                "    root='./data', train=True, download=True, transform=transform\n",
                ")\n",
                "mnist_test = torchvision.datasets.MNIST(\n",
                "    root='./data', train=False, download=True, transform=transform\n",
                ")\n",
                "\n",
                "# Use subset for quick demo\n",
                "mnist_train_small = Subset(mnist_train, range(1000))\n",
                "mnist_test_small = Subset(mnist_test, range(200))\n",
                "\n",
                "train_loader = DataLoader(mnist_train_small, batch_size=32, shuffle=True)\n",
                "test_loader = DataLoader(mnist_test_small, batch_size=32, shuffle=False)\n",
                "\n",
                "print(f\"MNIST train: {len(mnist_train_small)} samples\")\n",
                "print(f\"MNIST test: {len(mnist_test_small)} samples\")\n",
                "\n",
                "# Visualize samples\n",
                "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
                "for i, ax in enumerate(axes.flat):\n",
                "    img, label = mnist_train[i]\n",
                "    ax.imshow(img.squeeze(), cmap='gray')\n",
                "    ax.set_title(f'Label: {label}')\n",
                "    ax.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple SNN classifier for MNIST\n",
                "class SNNMNISTClassifier(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        \n",
                "        # Flatten 28x28 image to 784\n",
                "        # Use 2-layer SNN\n",
                "        self.synapsis1 = Synapsis(784, 256)\n",
                "        self.gif1 = GIFNeuron(256, 256, L=8)\n",
                "        \n",
                "        self.synapsis2 = Synapsis(256, 128)\n",
                "        self.gif2 = GIFNeuron(128, 128, L=8)\n",
                "        \n",
                "        self.classifier = nn.Linear(128, 10)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # x: (batch, 1, 28, 28)\n",
                "        batch_size = x.shape[0]\n",
                "        \n",
                "        # Flatten and add time dimension\n",
                "        x = x.view(batch_size, -1, 784)  # (batch, 1, 784)\n",
                "        \n",
                "        # Layer 1\n",
                "        h1, _ = self.synapsis1(x)\n",
                "        s1, _ = self.gif1(h1)\n",
                "        \n",
                "        # Layer 2\n",
                "        h2, _ = self.synapsis2(s1)\n",
                "        s2, _ = self.gif2(h2)\n",
                "        \n",
                "        # Pool spikes over time and classify\n",
                "        pooled = s2.mean(dim=1)  # (batch, 128)\n",
                "        logits = self.classifier(pooled)\n",
                "        \n",
                "        return logits, {'spike_rate_l1': s1.mean(), 'spike_rate_l2': s2.mean()}\n",
                "\n",
                "mnist_model = SNNMNISTClassifier().to(device)\n",
                "print(f\"MNIST model parameters: {sum(p.numel() for p in mnist_model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick inference test\n",
                "mnist_model.eval()\n",
                "with torch.no_grad():\n",
                "    # Get a batch\n",
                "    images, labels = next(iter(test_loader))\n",
                "    images, labels = images.to(device), labels.to(device)\n",
                "    \n",
                "    # Forward pass\n",
                "    logits, info = mnist_model(images)\n",
                "    preds = logits.argmax(dim=1)\n",
                "    \n",
                "    # Calculate accuracy\n",
                "    acc = (preds == labels).float().mean()\n",
                "    \n",
                "    print(f\"Random initialization accuracy: {acc:.2%}\")\n",
                "    print(f\"Spike rate layer 1: {info['spike_rate_l1']:.3f}\")\n",
                "    print(f\"Spike rate layer 2: {info['spike_rate_l2']:.3f}\")\n",
                "    \n",
                "    # Visualize predictions\n",
                "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
                "    for i, ax in enumerate(axes.flat):\n",
                "        ax.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
                "        correct = '✓' if preds[i] == labels[i] else '✗'\n",
                "        ax.set_title(f'True:{labels[i]} Pred:{preds[i]} {correct}')\n",
                "        ax.axis('off')\n",
                "    plt.suptitle('SNN Predictions (Untrained)', fontsize=14)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Summary\n",
                "\n",
                "## Key Takeaways\n",
                "\n",
                "1. **Prosody Extraction**: Amplitude/pitch/boundary channels capture emotional content from text\n",
                "2. **Attention Modulation**: k-WTA selects salient tokens, modulates GIF neuron thresholds\n",
                "3. **Preset Configurations**: Different presets (analytical/emotional/etc) emphasize different prosody features\n",
                "4. **SNN Components**: GIF neurons + Synapsis layers provide efficient spike-based processing\n",
                "\n",
                "## Component Status\n",
                "- ✅ Multi-Channel Spiking Attention\n",
                "- ✅ Prosody-Modulated GIF Neurons\n",
                "- ✅ SNN Transformer Operations\n",
                "- ✅ Spike↔Continuous Bridges\n",
                "- ✅ Full Language Zone Integration\n",
                "\n",
                "## Next Steps\n",
                "- Full training on GoEmotions\n",
                "- Liquid MoE integration (async routing)\n",
                "- Energy tracking and optimization\n",
                "- Multi-task learning across emotions"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}